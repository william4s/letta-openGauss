#!/usr/bin/env python3
"""
LettaæœåŠ¡å™¨æ—¥å¿—åˆ†æå·¥å…·
åˆ†æå®¡è®¡æ—¥å¿—ã€æ€§èƒ½æŒ‡æ ‡å’Œé”™è¯¯æ¨¡å¼
"""

import re
import json
import argparse
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Tuple, Optional
from pathlib import Path


class LettaLogAnalyzer:
    """LettaæœåŠ¡å™¨æ—¥å¿—åˆ†æå™¨"""
    
    def __init__(self, log_file: str):
        self.log_file = Path(log_file)
        self.audit_events = []
        self.api_calls = []
        self.errors = []
        self.database_issues = []
        self.performance_data = []
        
    def parse_log_file(self):
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        if not self.log_file.exists():
            raise FileNotFoundError(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
        
        with open(self.log_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    # è§£æå®¡è®¡äº‹ä»¶
                    if 'ğŸ” AUDIT |' in line or 'LettaServerAudit' in line:
                        self._parse_audit_event(line, line_num)
                    
                    # è§£æAPIè°ƒç”¨
                    elif '"GET ' in line or '"POST ' in line or '"PUT ' in line or '"DELETE ' in line:
                        self._parse_api_call(line, line_num)
                    
                    # è§£æé”™è¯¯ä¿¡æ¯
                    elif 'ERROR' in line or 'UNIQUE constraint failed' in line or 'could not open extension' in line:
                        self._parse_error(line, line_num)
                    
                    # è§£ææ•°æ®åº“é—®é¢˜
                    elif any(keyword in line for keyword in ['OpenGauss', 'postgresql', 'database', 'extension']):
                        self._parse_database_issue(line, line_num)
                
                except Exception as e:
                    print(f"è§£æç¬¬{line_num}è¡Œæ—¶å‡ºé”™: {e}")
                    continue
    
    def _parse_audit_event(self, line: str, line_num: int):
        """è§£æå®¡è®¡äº‹ä»¶"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = line.find('{"id":')
            if json_start != -1:
                json_str = line[json_start:]
                audit_data = json.loads(json_str)
                audit_data['line_number'] = line_num
                self.audit_events.append(audit_data)
        except json.JSONDecodeError:
            pass
    
    def _parse_api_call(self, line: str, line_num: int):
        """è§£æAPIè°ƒç”¨"""
        # åŒ¹é…APIè°ƒç”¨æ¨¡å¼: IP - "METHOD PATH" STATUS
        pattern = r'(\d+\.\d+\.\d+\.\d+):\d+ - "([A-Z]+) ([^"]+)" (\d+)'
        match = re.search(pattern, line)
        
        if match:
            ip, method, path, status = match.groups()
            
            # æå–å“åº”æ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰
            response_time = None
            time_match = re.search(r'(\d+)ms', line)
            if time_match:
                response_time = int(time_match.group(1))
            
            self.api_calls.append({
                'line_number': line_num,
                'ip': ip,
                'method': method,
                'path': path,
                'status': int(status),
                'response_time': response_time,
                'timestamp': self._extract_timestamp(line)
            })
    
    def _parse_error(self, line: str, line_num: int):
        """è§£æé”™è¯¯ä¿¡æ¯"""
        error_data = {
            'line_number': line_num,
            'timestamp': self._extract_timestamp(line),
            'content': line,
            'type': 'unknown'
        }
        
        # åˆ†ç±»é”™è¯¯ç±»å‹
        if 'UNIQUE constraint failed' in line:
            error_data['type'] = 'database_constraint'
        elif 'could not open extension control file' in line:
            error_data['type'] = 'database_extension'
        elif 'ERROR' in line and 'audit' in line.lower():
            error_data['type'] = 'audit_system'
        elif 'HTTP' in line:
            error_data['type'] = 'http_error'
        
        self.errors.append(error_data)
    
    def _parse_database_issue(self, line: str, line_num: int):
        """è§£ææ•°æ®åº“ç›¸å…³é—®é¢˜"""
        issue_data = {
            'line_number': line_num,
            'timestamp': self._extract_timestamp(line),
            'content': line,
            'severity': 'info'
        }
        
        # åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
        if 'ERROR' in line:
            issue_data['severity'] = 'error'
        elif 'WARNING' in line:
            issue_data['severity'] = 'warning'
        elif 'could not' in line or 'failed' in line:
            issue_data['severity'] = 'error'
        
        self.database_issues.append(issue_data)
    
    def _extract_timestamp(self, line: str) -> Optional[str]:
        """ä»æ—¥å¿—è¡Œä¸­æå–æ—¶é—´æˆ³"""
        # åŒ¹é…ISOæ—¶é—´æˆ³
        iso_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d+)'
        match = re.search(iso_pattern, line)
        if match:
            return match.group(1)
        
        # åŒ¹é…ç®€å•æ—¶é—´æˆ³
        simple_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})'
        match = re.search(simple_pattern, line)
        if match:
            return match.group(1)
        
        return None
    
    def analyze_audit_events(self) -> Dict:
        """åˆ†æå®¡è®¡äº‹ä»¶"""
        if not self.audit_events:
            return {"message": "æœªæ‰¾åˆ°å®¡è®¡äº‹ä»¶"}
        
        # äº‹ä»¶ç±»å‹ç»Ÿè®¡
        event_types = Counter(event.get('event_type', 'unknown') for event in self.audit_events)
        
        # é£é™©åˆ†æ
        risk_scores = [event.get('risk_score', 0) for event in self.audit_events]
        high_risk_events = [e for e in self.audit_events if e.get('risk_score', 0) >= 70]
        
        # ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡
        user_activities = defaultdict(int)
        for event in self.audit_events:
            user_id = event.get('user_id', 'anonymous')
            user_activities[user_id] += 1
        
        # æ€§èƒ½ç»Ÿè®¡
        response_times = [e.get('response_time_ms') for e in self.audit_events if e.get('response_time_ms')]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            'total_events': len(self.audit_events),
            'event_types': dict(event_types.most_common(10)),
            'risk_analysis': {
                'high_risk_count': len(high_risk_events),
                'avg_risk_score': sum(risk_scores) / len(risk_scores) if risk_scores else 0,
                'max_risk_score': max(risk_scores) if risk_scores else 0
            },
            'user_activities': dict(user_activities),
            'performance': {
                'avg_response_time': round(avg_response_time, 2),
                'total_responses': len(response_times),
                'slow_requests': len([t for t in response_times if t > 1000])  # > 1ç§’
            }
        }
    
    def analyze_api_calls(self) -> Dict:
        """åˆ†æAPIè°ƒç”¨"""
        if not self.api_calls:
            return {"message": "æœªæ‰¾åˆ°APIè°ƒç”¨è®°å½•"}
        
        # ç«¯ç‚¹ç»Ÿè®¡
        endpoints = Counter(call['path'] for call in self.api_calls)
        
        # çŠ¶æ€ç ç»Ÿè®¡
        status_codes = Counter(call['status'] for call in self.api_calls)
        
        # æ€§èƒ½åˆ†æ
        response_times = [call['response_time'] for call in self.api_calls if call['response_time']]
        
        # é”™è¯¯åˆ†æ
        error_calls = [call for call in self.api_calls if call['status'] >= 400]
        
        return {
            'total_calls': len(self.api_calls),
            'top_endpoints': dict(endpoints.most_common(10)),
            'status_codes': dict(status_codes),
            'performance': {
                'avg_response_time': round(sum(response_times) / len(response_times), 2) if response_times else 0,
                'slow_requests': len([t for t in response_times if t > 1000])
            },
            'errors': {
                'count': len(error_calls),
                'error_endpoints': Counter(call['path'] for call in error_calls)
            }
        }
    
    def analyze_errors(self) -> Dict:
        """åˆ†æé”™è¯¯"""
        if not self.errors:
            return {"message": "æœªå‘ç°é”™è¯¯"}
        
        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_types = Counter(error['type'] for error in self.errors)
        
        # æ•°æ®åº“ç›¸å…³é”™è¯¯
        db_errors = [e for e in self.errors if 'database' in e['type']]
        audit_errors = [e for e in self.errors if e['type'] == 'audit_system']
        
        return {
            'total_errors': len(self.errors),
            'error_types': dict(error_types),
            'database_errors': len(db_errors),
            'audit_errors': len(audit_errors),
            'top_errors': [
                {
                    'type': error['type'],
                    'line': error['line_number'],
                    'content': error['content'][:100] + '...' if len(error['content']) > 100 else error['content']
                }
                for error in self.errors[:10]
            ]
        }
    
    def analyze_database_issues(self) -> Dict:
        """åˆ†ææ•°æ®åº“é—®é¢˜"""
        if not self.database_issues:
            return {"message": "æœªå‘ç°æ•°æ®åº“é—®é¢˜"}
        
        # ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
        severity_count = Counter(issue['severity'] for issue in self.database_issues)
        
        # æ‰©å±•ç›¸å…³é—®é¢˜
        extension_issues = [i for i in self.database_issues if 'extension' in i['content']]
        opengauss_issues = [i for i in self.database_issues if 'OpenGauss' in i['content']]
        
        return {
            'total_issues': len(self.database_issues),
            'severity_distribution': dict(severity_count),
            'extension_issues': len(extension_issues),
            'opengauss_issues': len(opengauss_issues),
            'critical_issues': [
                {
                    'severity': issue['severity'],
                    'line': issue['line_number'],
                    'content': issue['content'][:150] + '...' if len(issue['content']) > 150 else issue['content']
                }
                for issue in self.database_issues if issue['severity'] == 'error'
            ]
        }
    
    def generate_report(self, output_file: str):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        audit_analysis = self.analyze_audit_events()
        api_analysis = self.analyze_api_calls()
        error_analysis = self.analyze_errors()
        db_analysis = self.analyze_database_issues()
        
        report = f"""# ğŸ“Š LettaæœåŠ¡å™¨æ—¥å¿—åˆ†ææŠ¥å‘Š
{'='*50}

## ğŸš€ æœåŠ¡å™¨åŸºæœ¬ä¿¡æ¯
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ—¥å¿—æ–‡ä»¶**: {self.log_file}
- **æ€»æ—¥å¿—è¡Œæ•°**: {sum(1 for _ in open(self.log_file, encoding='utf-8', errors='ignore'))}

## ğŸ“‹ å®¡è®¡äº‹ä»¶æ€»è§ˆ
- **æ€»å®¡è®¡äº‹ä»¶æ•°**: {audit_analysis.get('total_events', 0)}
- **äº‹ä»¶ç±»å‹åˆ†å¸ƒ**:
"""
        
        for event_type, count in audit_analysis.get('event_types', {}).items():
            report += f"  - {event_type}: {count}\n"
        
        report += f"""
## ğŸŒ APIè°ƒç”¨ç»Ÿè®¡
- **æ€»APIè°ƒç”¨æ¬¡æ•°**: {api_analysis.get('total_calls', 0)}
- **çƒ­é—¨APIç«¯ç‚¹** (å‰10):
"""
        
        for endpoint, count in api_analysis.get('top_endpoints', {}).items():
            report += f"  - {endpoint}: {count}æ¬¡\n"
        
        report += f"""
## ğŸ‘¥ ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡
"""
        for user, count in audit_analysis.get('user_activities', {}).items():
            report += f"- {user}: {count}æ¬¡æ´»åŠ¨\n"
        
        report += f"""
## ğŸ¤– æ™ºèƒ½ä½“æ´»åŠ¨ç»Ÿè®¡
- æ™ºèƒ½ä½“ç›¸å…³APIè°ƒç”¨: {len([c for c in self.api_calls if 'agent' in c.get('path', '')])}
- æ¶ˆæ¯ç›¸å…³è°ƒç”¨: {len([c for c in self.api_calls if 'message' in c.get('path', '')])}

## âš¡ æ€§èƒ½æŒ‡æ ‡
- **å¹³å‡å“åº”æ—¶é—´**: {audit_analysis.get('performance', {}).get('avg_response_time', 0)}ms
- **æ…¢è¯·æ±‚æ•°é‡**: {audit_analysis.get('performance', {}).get('slow_requests', 0)}
- **APIå¹³å‡å“åº”æ—¶é—´**: {api_analysis.get('performance', {}).get('avg_response_time', 0)}ms

## âŒ é”™è¯¯åˆ†æ
- **ç³»ç»Ÿé”™è¯¯æ€»æ•°**: {error_analysis.get('total_errors', 0)}
- **æ•°æ®åº“ç›¸å…³é—®é¢˜**: {db_analysis.get('total_issues', 0)}
- **å®¡è®¡ç³»ç»Ÿé”™è¯¯**: {error_analysis.get('audit_errors', 0)}

### ğŸ” å…³é”®é”™è¯¯è¯¦æƒ…:
"""
        
        for error in error_analysis.get('top_errors', [])[:5]:
            report += f"- **{error['type']}** (è¡Œ{error['line']}): {error['content']}\n"
        
        report += f"""
## ğŸ—„ï¸ æ•°æ®åº“é—®é¢˜åˆ†æ
- **æ€»é—®é¢˜æ•°**: {db_analysis.get('total_issues', 0)}
- **æ‰©å±•ç›¸å…³é—®é¢˜**: {db_analysis.get('extension_issues', 0)}
- **OpenGaussç›¸å…³é—®é¢˜**: {db_analysis.get('opengauss_issues', 0)}

### ğŸš¨ ä¸¥é‡é—®é¢˜:
"""
        
        for issue in db_analysis.get('critical_issues', [])[:5]:
            report += f"- **{issue['severity'].upper()}** (è¡Œ{issue['line']}): {issue['content']}\n"
        
        report += f"""
## â° æ´»åŠ¨æ—¶é—´åˆ†å¸ƒ
"""
        # ç®€å•çš„æ—¶é—´åˆ†å¸ƒç»Ÿè®¡
        hourly_stats = defaultdict(int)
        for event in self.audit_events:
            timestamp = event.get('timestamp', '')
            if timestamp:
                try:
                    hour = datetime.fromisoformat(timestamp.replace('Z', '')).hour
                    hourly_stats[hour] += 1
                except:
                    pass
        
        for hour in sorted(hourly_stats.keys()):
            report += f"- **{hour:02d}:00**: {hourly_stats[hour]}\n"
        
        report += f"""
## ğŸ“ æ€»ç»“å’Œå»ºè®®
### ç³»ç»Ÿå¥åº·çŠ¶æ€
- **æ•´ä½“çŠ¶æ€**: {'è‰¯å¥½ âœ…' if error_analysis.get('total_errors', 0) < 10 else 'éœ€è¦å…³æ³¨ âš ï¸'}
- **é”™è¯¯ç‡**: {(error_analysis.get('total_errors', 0) / max(audit_analysis.get('total_events', 1), 1) * 100):.2f}%

### ğŸ”§ ç´§æ€¥ä¿®å¤å»ºè®®
1. **æ•°æ®åº“å…¼å®¹æ€§**: è§£å†³OpenGaussä¸PostgreSQL vectorç±»å‹çš„å…¼å®¹é—®é¢˜
2. **å®¡è®¡ç³»ç»Ÿ**: ä¼˜åŒ–å®¡è®¡äº‹ä»¶IDç”Ÿæˆï¼Œé¿å…å†²çª
3. **æ€§èƒ½ä¼˜åŒ–**: å…³æ³¨æ…¢è¯·æ±‚ï¼Œä¼˜åŒ–å“åº”æ—¶é—´
4. **ç›‘æ§å¢å¼º**: æ·»åŠ æ›´è¯¦ç»†çš„ç”¨æˆ·ä¼šè¯è·Ÿè¸ª

## ğŸ” å®¡è®¡ç³»ç»Ÿè¯„ä¼°
### å®¡è®¡è¦†ç›–åº¦
âœ… **å·²è¦†ç›–çš„æ–¹é¢**:
- APIè°ƒç”¨è¿½è¸ª
- æ™ºèƒ½ä½“æ´»åŠ¨ç›‘æ§
- é£é™©è¯„åˆ†è¯„ä¼°
- å“åº”æ—¶é—´ç›‘æ§

âš ï¸ **å¾…æ”¹è¿›çš„æ–¹é¢**:
- å…·ä½“å¯¹è¯å†…å®¹åˆ†æ
- é‡‘èæ•æ„Ÿæ•°æ®æ£€æµ‹
- ç”¨æˆ·èº«ä»½éªŒè¯å®¡è®¡
- åˆè§„æ€§æ£€æŸ¥

### ğŸ› ï¸ å»ºè®®çš„ä¸‹ä¸€æ­¥æ“ä½œ
1. è¿è¡Œæ•°æ®åº“å…¼å®¹æ€§ä¿®å¤å·¥å…·: `python fix_opengauss_compatibility.py`
2. é‡å¯lettaæœåŠ¡å™¨å¹¶è§‚å¯Ÿé”™è¯¯æ˜¯å¦å‡å°‘
3. å®æ–½ç”¨æˆ·èº«ä»½éªŒè¯å®¡è®¡
4. æ·»åŠ é‡‘èæ–‡æ¡£ç‰¹å®šçš„åˆè§„æ€§æ£€æŸ¥
"""
        
        # ä¿å­˜æŠ¥å‘Š
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        
        # è¿”å›åˆ†ææ‘˜è¦
        return {
            'audit_events': audit_analysis.get('total_events', 0),
            'api_calls': api_analysis.get('total_calls', 0),
            'errors': error_analysis.get('total_errors', 0),
            'database_issues': db_analysis.get('total_issues', 0)
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LettaæœåŠ¡å™¨æ—¥å¿—åˆ†æå·¥å…·")
    parser.add_argument("--log-file", required=True, help="æ—¥å¿—æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="./logs/audit_analysis_report.md", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    try:
        analyzer = LettaLogAnalyzer(args.log_file)
        print("ğŸ“„ è§£ææ—¥å¿—æ–‡ä»¶...")
        analyzer.parse_log_file()
        
        print("ğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        summary = analyzer.generate_report(args.output)
        
        print("\n" + "="*50)
        print("ğŸ“ˆ åˆ†ææ‘˜è¦:")
        print(f"- å®¡è®¡äº‹ä»¶: {summary['audit_events']}")
        print(f"- APIè°ƒç”¨: {summary['api_calls']}")
        print(f"- é”™è¯¯æ•°é‡: {summary['errors']}")
        print(f"- æ•°æ®åº“é—®é¢˜: {summary['database_issues']}")
        print("="*50)
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())